{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYpPIrwqv+mOIYffpR0W9a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JOWIN-JOSEPH-RAJU/AI-Data_Science-Lab/blob/main/Exp_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVtSNdEC0HwU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAIVA QUESTIONS\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1.   What is KNN?\n",
        "2.   what is Irish Dataset ? which are the features and class labels?\n",
        "3.   From sklearn dataset import load_iris. what is the use of this\n",
        "4. X=iris.data() what is the data attribute it contains\n",
        "5. y=iris.target what does the target attribute do ?\n",
        "6. what is  model training and model evaluation\n",
        "7. why do we split the data into trainning and test dat set\n",
        "8. which is an ideal training and test dataset\n",
        "9. how do we split the dataset into training and testing data set. Explain train test split ?\n",
        "10. prediction we made on which type of data?how do you made prediction ?what is KNN predict\n",
        "11. what is scikit learn?\n",
        "12. how do you create and train the KNN classifier .what does kneighbour classifier (n_neighbours = 3) mean\n",
        "13. what is accuracy of a model ? how do you find the accuracy of KNN classifier created ?what is accuracy score?\n",
        "14. HOW DO YOU PRINT BOTH CORRECT & WRONG PREDITION & EXPLAIN THE CODE\n",
        "\n"
      ],
      "metadata": {
        "id": "hRqfvayh0MTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is KNN?\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*  The K-Nearest Neighbors (KNN) algorithm is a simple, supervised machine learning algorithm that can be used for both classification and regression tasks. It works by finding the K most similar training examples to a new data point and then predicting the label of the new data point based on the labels of the K nearest neighbors.\n",
        "\n",
        "* Advantages of KNN\n",
        "\n",
        "   * KNN is a simple and easy-to-understand algorithm.\n",
        "   * KNN is very flexible and can be used for both classification and regression tasks.\n",
        "   * KNN is relatively non-parametric, which means that it does not make any assumptions about the underlying distribution of the data.\n",
        "   * KNN is very adaptable and can learn from new data as it becomes available.\n",
        "\n",
        "* Disadvantages of KNN\n",
        "\n",
        "   * KNN can be computationally expensive, especially for large datasets.\n",
        "  *  KNN is sensitive to the choice of the K parameter. If K is too small, the algorithm can be overfitting and will not generalize well to new data. If K is too large, the algorithm can be underfitting and will not be able to learn the patterns in the data.\n",
        "   * KNN can be sensitive to the choice of distance metric. Different distance metrics can produce different results, so it is important to choose a distance metric that is appropriate for the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "1m34pYVq0JBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# what is Irish Dataset ? which are the features and class labels?\n",
        "\n",
        "---\n",
        "* The Iris Dataset is a classic machine learning dataset that consists of 150 samples of 3 species of Iris flowers (Iris setosa, Iris virginica, and Iris versicolor). Each sample has 4 features: sepal length, sepal width, petal length, and petal width. The dataset is often used to test machine learning algorithms, such as classification and regression algorithms.\n",
        "\n",
        "* Features:\n",
        "\n",
        "    * Sepal length (cm)\n",
        "    * Sepal width (cm)\n",
        "    * Petal length (cm)\n",
        "    * Petal width (cm)\n",
        "* Class labels:\n",
        "\n",
        "    * Iris setosa (0)\n",
        "    * Iris virginica (1)\n",
        "    * Iris versicolor (2)\n"
      ],
      "metadata": {
        "id": "YiLrGPWD3eUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From sklearn dataset import load_iris. what is the use of this\n",
        "\n",
        "---\n",
        "* The **sklearn.datasets.load_iris() **function is used to load the Iris dataset into a Python program\n",
        "* The load_iris() function returns a dictionary-like object that contains the following attributes:\n",
        "\n",
        "    * data: A NumPy array containing the feature values for each sample.\n",
        "    * target: A NumPy array containing the class labels for each sample.\n",
        "    * target_names: A list of the class names.\n",
        "    * feature_names: A list of the feature names.\n",
        "    * DESCR: A full description of the dataset.\n"
      ],
      "metadata": {
        "id": "O24DxBU46Fq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "print(iris.data)\n",
        "print(iris.target)\n",
        "print(iris.target_names)\n",
        "print(iris.feature_names)\n",
        "print(iris.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxeE5Eur8Lh5",
        "outputId": "33303d59-11e0-4ab3-a56b-667597e9c5bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X=iris.data() what is the data attribute it contains\n",
        "\n",
        "---\n",
        "The iris.data() attribute contains a NumPy array containing the feature values for each sample in the Iris dataset. Each row in the array represents a sample, and each column represents a feature. The Iris dataset has 4 features: sepal length, sepal width, petal length, and petal width.\n"
      ],
      "metadata": {
        "id": "CnRdLGmJ9fOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "\n",
        "# Print the first 5 rows of the feature array\n",
        "print(X[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b_40i9V-VPn",
        "outputId": "8ae0d6bc-4a81-41ba-f50f-f353050ec5c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# y=iris.target what does the target attribute do ?\n",
        "\n",
        "---\n",
        "he iris.target attribute contains a NumPy array containing the class labels for each sample in the Iris dataset. Each element in the array represents the class label for a sample. The Iris dataset has 3 classes: Iris setosa, Iris virginica, and Iris versicolor.\n"
      ],
      "metadata": {
        "id": "b0rPXYC9_wIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "y=iris.target\n",
        "print(y[100:150])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUXlpO3pAK39",
        "outputId": "9b1416ce-6300-40d4-e5f8-ea783b37ca54"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# what is model trainning and model evaluation\n",
        "\n",
        "---\n",
        "* Model training is the process of teaching a machine learning model to perform a specific task. This is done by feeding the model a set of training data, which consists of input data and the corresponding output data. The model learns to predict the output data for new input data by finding patterns in the training data.\n",
        "* Model evaluation is the process of assessing the performance of a trained machine learning model on a held-out test set. The test set is a set of data that the model was not trained on. By evaluating the model on the test set, we can get an unbiased estimate of how well the model will perform on new data.\n",
        "\n",
        "1.Collect a dataset of training data.\n",
        "2.Split the dataset into a training set and a test set.\n",
        "3.Choose a machine learning algorithm\n",
        "4.Train the model on the training set\n",
        "5.Evaluate the model on the test set"
      ],
      "metadata": {
        "id": "keAemJuwA_WV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# why do we split the data into trainning and test dat set\n",
        "\n",
        "---\n",
        "We split the data into training and test datasets for two main reasons:\n",
        "\n",
        "\n",
        "    1. To avoid overfitting. Overfitting occurs when a machine learning model learns the training data too well and is unable to generalize to new data. By splitting the data into training and test datasets, we can train the model on the training set and evaluate its performance on the test set. If the model performs poorly on the test set, then we know that it is overfitting the training data and we need to take steps to address this, such as collecting more training data or using a different model architecture.\n",
        "    2. To get an unbiased estimate of the model's performance. If we evaluate the model on the same data that it was trained on, then we are likely to get an overly optimistic estimate of its performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "zVVTJX1EB-Qj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# how do we split the dataset into training and testing data set.\n",
        "\n",
        "---\n",
        "\n",
        "* To split the dataset into training and testing datasets, we can use the train_test_split() function from the scikit-learn library in Python.\n",
        "\n",
        "* The train_test_split() function takes the following arguments:\n",
        "\n",
        "    * X: The input data.\n",
        "    * y: The output data.\n",
        "    * test_size: The proportion of the data to be used for the test set. The default value is 0.25.\n",
        "    * random_state: An integer seed used to shuffle the data before splitting it. This ensures that the split is reproducible.\n",
        "\n",
        "* The function returns four NumPy arrays:\n",
        "\n",
        "    * X_train: The training input data.\n",
        "    * X_test: The test input data.\n",
        "    * y_train: The training output data.\n",
        "    * y_test: The test output data.\n",
        "\n"
      ],
      "metadata": {
        "id": "mtNN6Gt-DYKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "Y=iris.target\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into training and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "UedtbriMDjeM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explain train test split ?\n",
        "\n",
        "---\n",
        "\n",
        "* Train-test split is a technique used to evaluate the performance of machine learning models. It involves splitting the dataset into two subsets: a training set and a test set. The training set is used to train the model, and the test set is used to evaluate the model's performance on unseen data.\n",
        "\n",
        "\n",
        "    *  Split the dataset into two subsets: the training set and the test set. The training set is typically larger than the test set, as it is used to train the model. The test set should be large enough to provide a reliable estimate of the model's performance on unseen data.\n",
        "    *  Train the model on the training set. The model is trained by feeding it the training data and allowing it to learn the patterns in the data.\n",
        "    *  Evaluate the model on the test set. The model's performance is evaluated by feeding it the test data and predicting the output labels. The predictions are then compared to the actual labels to assess the model's accuracy.\n"
      ],
      "metadata": {
        "id": "Qa3A9tV6Ej6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prediction we made on which type of data?how do you made prediction ?what is KNN predict\n",
        "\n",
        "---\n",
        "1.We can make predictions on any type of data that can be represented as a numerical vector. For example, we can make predictions on data that represents images, text, or audio.\n",
        "\n",
        "2.To make predictions using KNN, we first need to train a KNN model. This involves feeding the model a set of training data, which consists of input data and the corresponding output labels. The model learns to predict the output labels for new input data by finding the K most similar training examples and averaging the output labels for those examples.\n"
      ],
      "metadata": {
        "id": "vIbzSHVZEg8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the training data\n",
        "\n",
        "\n",
        "# Create a KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Train the model\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on new data\n",
        "X_new = np.array([[7,5 ]])\n",
        "y_pred = knn.predict(X_new)\n",
        "\n",
        "# Print the predictions\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o64mhEmmFtm1",
        "outputId": "67c772c1-c03c-4af9-f72a-c4ff2e76f39d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# what is scikit learn?\n",
        "\n",
        "---\n",
        "Scikit-learn is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support-vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.\n",
        "\n"
      ],
      "metadata": {
        "id": "rD07wcaTFtC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# how do you create and train the KNN classifier .what does kneighbour classifier (n_neighbours = 3) mean\n",
        "\n",
        "---\n",
        "* To create and train a KNN classifier in Python, we can use the KNeighborsClassifier class from the scikit-learn library.\n",
        "\n",
        "* import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "Load the training data\n",
        "X_train = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "y_train = np.array([0, 1, 2])\n",
        "\n",
        "Create a KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "Train the model\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6k2Oaj4WLLB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# what is accuracy of a model ? how do you find the accuracy of KNN classifier created ?what is accuracy score?\n",
        "\n",
        "---\n",
        "* Accuracy is a measure of how well a machine learning model performs on a test set. It is calculated as the percentage of correct predictions that the model makes on the test set.\n"
      ],
      "metadata": {
        "id": "8mxayfEENYeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN ALGORITH\n",
        "AIM :IMPLEMENT K NEAREST NEIGHBOUR ALGOURITHM TO CLASSIFY ANY DATA SET PRINT BOTH CORRECT AND WRONG PREDICTIONS ML LIBRARY CLASS CAN BE USED FOR THIS PROBLEM ASSUME K = 3"
      ],
      "metadata": {
        "id": "TjeQcBZI5Nlh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "S29mlmE9QC1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROGRAM\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3PFGafnqQDyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "iris=load_iris()\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred=knn.predict(X_test)\n",
        "print(\"accuracy of the model :\",knn.score(X_test,y_test )*100,\"%\\n\")\n",
        "print(\"ACTUAL \\t\\t PREDICTED \\t PREDICTION\")\n",
        "for i in range (len(X_test)):\n",
        "  if y_pred[i]==y_test[i]:\n",
        "    print(iris.target_names[y_test[i]],\" \\t\",iris.target_names[y_pred[i]],\"\\t\",\"Correct\")\n",
        "  else:\n",
        "    print(iris.target_names[y_test[i]],\"\\t\",iris.target_names[y_pred[i]],\"\\t\",\"Incorrect\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H5kSRXXFrr3",
        "outputId": "55469be8-0442-4d51-f2d7-3ee45abe2552"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of the model : 100.0 %\n",
            "\n",
            "ACTUAL \t\t PREDICTED \t PREDICTION\n",
            "versicolor  \t versicolor \t Correct\n",
            "setosa  \t setosa \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "versicolor  \t versicolor \t Correct\n",
            "versicolor  \t versicolor \t Correct\n",
            "setosa  \t setosa \t Correct\n",
            "versicolor  \t versicolor \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "versicolor  \t versicolor \t Correct\n",
            "versicolor  \t versicolor \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "setosa  \t setosa \t Correct\n",
            "setosa  \t setosa \t Correct\n",
            "setosa  \t setosa \t Correct\n",
            "setosa  \t setosa \t Correct\n",
            "versicolor  \t versicolor \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "versicolor  \t versicolor \t Correct\n",
            "versicolor  \t versicolor \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "setosa  \t setosa \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "setosa  \t setosa \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "virginica  \t virginica \t Correct\n",
            "setosa  \t setosa \t Correct\n",
            "setosa  \t setosa \t Correct\n"
          ]
        }
      ]
    }
  ]
}
